# How to use OpenAI APIs right from Postgres to implement semantic search and GPT chat

> æˆ‘æ¯å¤©éƒ½ä¼šå‘å¸ƒä¸€ç¯‡æ–°çš„ PostgreSQL "howto" æ–‡ç« ã€‚åŠ å…¥æˆ‘çš„æ—…ç¨‹å§ â€” è®¢é˜…ã€æä¾›åé¦ˆã€åˆ†äº«ï¼

ä»Šå¤©ï¼Œæˆ‘ä»¬å°†åœ¨ Postgres ä¸­å®ç° RAG ([Retrieval Augmented Generation](https://en.wikipedia.org/wiki/Prompt_engineering#Retrieval-augmented_generation])) ï¼š

1. å°†å®Œæ•´çš„ Postgres æäº¤å†å²åŠ è½½åˆ° Postgres è¡¨ä¸­ã€‚
2. ä½¿ç”¨ `plpython3u` (æŸäº›æ‰˜ç®¡æœåŠ¡ä¸Šä¸å¯ç”¨ï¼Œå¦‚ RDS)ï¼Œä» Postgres ä¸­ç›´æ¥è°ƒç”¨ OpenAI APIã€‚

> âš ï¸ æ³¨æ„ï¼šè¿™ç§æ–¹æ³•ä¸èƒ½å¾ˆå¥½åœ°æ‰©å±•ï¼Œå› æ­¤ä¸æ¨èç”¨äºå¤§å‹ç”Ÿäº§é›†ç¾¤ã€‚è¯·å°†å…¶è§†ä¸ºä¸€ç§å¨±ä¹æˆ–ç”¨äºå°å‹é¡¹ç›®/æœåŠ¡çš„æ–¹å¼ã€‚

3. å¯¹äºæ¯ä¸ªæäº¤ï¼Œç”Ÿæˆ OpenAI åµŒå…¥å¹¶å°†å…¶å­˜å‚¨ä¸º"vector"æ ¼å¼ (`pgvector`)ã€‚ 
4. ä½¿ç”¨è¯­ä¹‰æœç´¢æŸ¥æ‰¾æäº¤ï¼Œé€šè¿‡ `pgvector` çš„ HNSW ç´¢å¼•åŠ é€Ÿæœç´¢ã€‚ 
5. æœ€åï¼Œé€šè¿‡ OpenAI GPT4 å®ç°"ä¸æäº¤å†å²å¯¹è¯"ã€‚

(Inspired by: [@jonatasdp's Tweet](https://twitter.com/jonatasdp/status/1714711585191596419))

## å‡†å¤‡å·¥ä½œ

é¦–å…ˆï¼Œå®‰è£…æ‰©å±•ï¼š

```sql
create extension if not exists plpython3u;
create extension if not exists vector;
```

ç„¶åï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ª [OpenAI API key](https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key)ã€‚æˆ‘ä»¬å°†å…¶å­˜å‚¨ä¸ºå½“å‰æ•°æ®åº“å®šä¹‰çš„è‡ªå®šä¹‰ GUCã€‚

> âš ï¸ æ³¨æ„ï¼šè¿™ç§å­˜å‚¨æ–¹å¼ä¸å¤Ÿå®‰å…¨ï¼›æˆ‘ä»¬ä»…ä¸ºç®€åŒ–æ“ä½œä½¿ç”¨æ­¤æ–¹æ³•ï¼š

```sql
do $$ begin
 execute(
   format(
     'alter database %I set opanai.api_key = %L',
     current_database(),
     'sk-XXXXXXXXXXXX'
   )
 );
end $$;
```

------

## ä»Gitå¯¼å…¥æäº¤å†å²

åˆ›å»ºä¸€ä¸ªè¡¨æ¥å­˜å‚¨ Git æäº¤è®°å½•ï¼š

```bash
psql -X \
  -c "create table commit_logs (
    id bigserial primary key,
    hash text not null,
    created_at timestamptz not null,
    authors text,
    message text,
    embedding vector(1536)
  )" \
  -c "create unique index on commit_logs(hash)"
```

ç°åœ¨ï¼Œå…‹éš† Postgres ä»£ç åº“å¹¶å°†å®Œæ•´çš„æäº¤å†å²å¯¼å‡ºåˆ° CSV æ–‡ä»¶ (æ³¨æ„å¤„ç†æäº¤æ¶ˆæ¯ä¸­çš„åŒå¼•å·è½¬ä¹‰)ï¼š

```bash
git clone https://gitlab.com/postgres/postgres.git
cd postgres

git log --all --pretty=format:'%H,%ad,%an,ğŸ˜%s %bğŸ˜ğŸ' --date=iso \
 | tr '\n' ' ' \
 | sed 's/"/""/g' \
 | sed 's/ğŸ˜/"/g' \
 | sed 's/ğŸ/\n/g' \
 > commit_logs.csv
```

å°†æäº¤å†å²ä» CSV æ–‡ä»¶åŠ è½½åˆ°è¡¨ä¸­ï¼š

```bash
psql -Xc "copy commit_logs(hash, created_at, authors, message)
   from stdin
   with delimiter ',' csv" \
 < commit_logs.csv

psql -X \
 -c "update commit_logs set hash = trim(hash)" \
 -c "vacuum full analyze commit_logs"
```

æˆªè‡³ 2023 å¹´ 10 æœˆï¼Œè¿™å°†ç”Ÿæˆçº¦ 88,000 è¡Œï¼Œæ¶µç›– Postgres å¼€å‘å†å²çš„è¿‘ 10,000 å¤© (è¶…è¿‡ 27 å¹´ â€” ç¬¬ä¸€æ¬¡æäº¤æ˜¯åœ¨ 1996-07-09)ã€‚

## åˆ›å»ºå¹¶å­˜å‚¨åµŒå…¥

ä»¥ä¸‹æ˜¯ç”¨äºä» OpenAI API è·å–æ¯ä¸ªæäº¤æ¡ç›®çš„å‘é‡çš„å‡½æ•°ï¼Œä½¿ç”¨ `plpython3u`ï¼ˆ`u` è¡¨ç¤º"ä¸å—ä¿¡ä»»"ï¼Œå…è®¸è¯¥å‡½æ•°ä¸å¤–éƒ¨ä¸–ç•Œé€šä¿¡)ï¼š

```sql
create or replace function openai_get_embedding(
 content text,
 api_key text default current_setting('opanai.api_key', true)
) returns vector(1536)
as $$
 import requests

 response = requests.post(
   'https://api.openai.com/v1/embeddings',
   headers={ 'Authorization': f'Bearer {api_key}' },
   json={
     'model': 'text-embedding-ada-002',
     'input': content.replace("\n", " ")
   }
 )

 if response.status_code >= 400:
   raise Exception(f"Failed. Code: {response.status_code}")

 return response.json()['data'][0]['embedding']
$$ language plpython3u;
```

å‡½æ•°åˆ›å»ºä¹‹åï¼Œå¼€å§‹è·å–å’Œå­˜å‚¨å‘é‡ã€‚æˆ‘ä»¬å°†åˆ†æ‰¹å¤„ç†ï¼Œé¿å…é•¿æ—¶é—´è¿è¡Œçš„äº‹åŠ¡ï¼Œä¸‡ä¸€å‘ç”Ÿæ•…éšœï¼Œä¸ä¼šä¸¢å¤±å¤§é‡æ•°æ®ï¼Œä¹Ÿä¸ä¼šé˜»å¡å¹¶å‘ä¼šè¯ (å¦‚æœæœ‰çš„è¯)ï¼š

```sql
with scope as (
 select hash
 from commit_logs
 where embedding is null
 order by id
 limit 5
), upd as (
 update commit_logs
 set embedding = openai_get_embedding(
   content := format(
     'Date: %s. Hash: %s. Message: %s',
     created_at,
     hash,
     message
   )
 )
 where hash in (
   select hash
   from scope
 )
 returning *
)
select
 count(embedding) as cnt_vectorized,
 max(http://upd.id) as latest_upd_id,
 round(
   max(http://upd.id)::numeric * 100 /
     (select max(http://c.id) from commit_logs as c),
   2
 )::text || '%' as progress,
 1 / count(*) as err_when_done
from upd
\watch .1
```

è¿™ä¸ªè¿‡ç¨‹å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œå¯èƒ½ä¼šè¶…è¿‡ä¸€ä¸ªå°æ—¶ï¼Œæ‰€ä»¥éœ€è¦è€å¿ƒç­‰å¾…ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨æ­¤è¿‡ç¨‹ä¸­å¼€å§‹ä½¿ç”¨ OpenAI çš„ API (è™½ç„¶åµŒå…¥åˆ›å»ºçš„æˆæœ¬éå¸¸ä½ï¼Œä¼°è®¡å¤§çº¦ä¸º 1 ç¾å…ƒï¼Œè¯¦è§[å®šä»·](https://openai.com/api/pricing/))ã€‚

ä¸€æ—¦å®Œæˆ (æˆ–è€…åœ¨éƒ¨åˆ†ç»“æœç”Ÿæˆå)ï¼Œå°±å¯ä»¥å¼€å§‹ä½¿ç”¨å®ƒã€‚

## è¯­ä¹‰æœç´¢

ä»¥ä¸‹æ˜¯ä½¿ç”¨è¯­ä¹‰æœç´¢æŸ¥æ‰¾æœ€ç›¸å…³æäº¤çš„ç®€å•ç¤ºä¾‹ï¼š

è¿™ä¸ªæ¦‚å¿µå¾ˆç®€å•ï¼š

1. é¦–å…ˆè°ƒç”¨ OpenAI APIï¼Œå°†æŸ¥è¯¢çš„æ–‡æœ¬å‘é‡åŒ–ã€‚
2. ç„¶åä½¿ç”¨ `pgvector` çš„ç›¸ä¼¼æ€§æœç´¢æŸ¥æ‰¾ K ä¸ªæœ€è¿‘é‚»ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ `HNSW` ç´¢å¼•ï¼Œè¿™è¢«è®¤ä¸ºæ˜¯ç›®å‰æœ€å¥½çš„æ–¹æ³•ä¹‹ä¸€ (å°½ç®¡æœ€æ—©æ˜¯åœ¨ [2016 ](https://arxiv.org/abs/1603.09320)å¹´æè¿°çš„)ï¼›å·²è¢«è®¸å¤šæ•°æ®åº“ç®¡ç†ç³»ç»Ÿæ·»åŠ ã€‚`pgvector` åœ¨ 0.5.0 ç‰ˆæœ¬ä¸­æ·»åŠ äº†è¯¥ç´¢å¼•ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™æ˜¯ä¸€ä¸ª `ANN` ç´¢å¼• â€” "è¿‘ä¼¼æœ€è¿‘é‚»"ï¼Œä¸ºäº†é€Ÿåº¦ï¼Œå®ƒå…è®¸äº§ç”Ÿä¸ä¸¥æ ¼çš„ç»“æœï¼Œä¸åƒ Postgres ä¸­çš„å¸¸è§„ç´¢å¼•ã€‚

åˆ›å»ºç´¢å¼•ï¼š

```bash
psql -Xc "create index on commit_logs
 using hnsw (embedding vector_cosine_ops)"
```

ç°åœ¨ï¼Œåœ¨ `psql` ä¸­æ‰§è¡Œæœç´¢ï¼š

```
select
 created_at,
 format(
   'https://gitlab.com/postgres/postgres/-/commit/%s',
   left(hash, 8)
 ),
 left(message, 150),
 authors,
 1 - (embedding <-> :'q_vector') as similarity
from commit_logs
order by embedding <-> :'q_vector'
limit 5 \gx
```

å¦‚æœç´¢å¼•å·²åˆ›å»ºå®Œæˆï¼Œç¬¬äºŒä¸ªæŸ¥è¯¢åº”è¯¥éå¸¸å¿«ã€‚ä½ å¯ä»¥ä½¿ç”¨ `EXPLAIN (ANALYZE, BUFFERS)` æ£€æŸ¥è®¡åˆ’å’Œæ‰§è¡Œè¯¦æƒ…ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å¾ˆå° (< 100 k)ï¼Œæ‰€ä»¥æœç´¢é€Ÿåº¦å¤§çº¦ä¸º 1 æ¯«ç§’ï¼Œç¼“å†²åŒºå‘½ä¸­/è¯»å–æ•°é‡å°äº 1000ã€‚pgvector æä¾›äº†ä¸€äº›é’ˆå¯¹ç´¢å¼•çš„è°ƒæ•´é€‰é¡¹ï¼Œè¯·æŸ¥çœ‹å…¶ [README](https://github.com/pgvector/pgvector/blob/master/README.md)ã€‚

ä»¥ä¸‹æ˜¯ä½¿ç”¨ `\watch` é™åˆ¶å¾ªç¯æŸ¥è¯¢ç»“æœçš„ç¤ºä¾‹ï¼š

```sql
-[ RECORD 1 ]------------------------------------------------------------------------------------------------------------------------------------------------------
created_at | 2023-04-06 17:18:14+00
format     | https://gitlab.com/postgres/postgres/-/commit/00beecfe
left       | psql: add an optional execution-count limit to \watch. \watch can now be told to stop after N executions of the query.  With the idea that we might wa
authors    | Tom Lane
similarity | 0.4774958262998097

-[ RECORD 2 ]------------------------------------------------------------------------------------------------------------------------------------------------------
created_at | 2023-09-18 14:19:25+00
format     | https://gitlab.com/postgres/postgres/-/commit/d726897c
left       | Fix psql's \? output for \watch It was reported as misaligned by Kyotaro, but it also needed to be turned into a single translatable phrase (like the
authors    | Alvaro Herrera
similarity | 0.4347320155373213

-[ RECORD 3 ]------------------------------------------------------------------------------------------------------------------------------------------------------
created_at | 2021-07-12 23:13:48+00
format     | https://gitlab.com/postgres/postgres/-/commit/7c09d279
left       | Add PSQL_WATCH_PAGER for psql's \watch command. Allow a pager to be used by the \watch command.  This works but isn't very useful with traditional pag
authors    | Thomas Munro
similarity | 0.4234620303691825
```

------

## åœ¨Postgresä¸­é€šè¿‡GPT4ä¸"Gitå†å²å¯¹è¯"

æœ€åï¼Œåˆ›å»ºä¸¤ä¸ªå‡½æ•°ï¼Œå¹¶æå‡ºæœ‰å…³ Postgres æäº¤å†å²çš„é—®é¢˜ï¼š

```sql
create or replace function openai_gpt_call(
 question text,
 data_to_embed text,
 model text default 'gpt-4',
 token_limit int default 4096,
 api_key text default current_setting('opanai.api_key', true)
) returns text
as $$
 import requests, json

 prompt = """Be terse. Discuss only Postgres and it's commits.
For commits, mention timestamp and hash.
CONTEXT (git commits):
---
%s
---
QUESTION: %s
""" % (data_to_embed[:2000], question)

 ### W: this code lacks error handling
 response = http://requests.post(
   'https://api.openai.com/v1/chat/completions',
   headers={ 'Authorization': f'Bearer {api_key}' },
   json={
     'model': model,
     'messages': [
         {"role": "user", "content": prompt}
     ],
     'max_tokens': token_limit,
     'temperature': 0
   }
 )

 if response.status_code >= 400:
   raise Exception(f"Failed. Code: {response.status_code}. Response: {response.text}")

 return response.json()['choices'][0]['message']['content']
$$ language plpython3u;

create or replace function openai_chat(
 in question text,
 in model text default 'gpt-4',
 out answer text
) as $$
 with q as materialized (
   select openai_get_embedding(
     question
   ) as emb
 ), find_enries as (
   select
     format(
       e'Created: %s, hash: %s, message: %s, committer: %s\n',
       created_at,
       left(hash, 8),
       message,
       authors
     ) as entry
   from commit_logs
   where embedding <=> (select emb from q) < 0.8
   order by embedding <=> (select emb from q)
   limit 10 -- adjust if needed
 )
 select openai_gpt_call(
   question := openai_chat.question,
   data_to_embed := string_agg(entry, e'\n'),
   model := openai_chat.model
 )
 from find_enries;
$$ language sql;
```

ç°åœ¨ï¼Œå¯ä»¥é€šè¿‡ `openai_chat(...)` æé—®ï¼Œä¾‹å¦‚ï¼š

```sql
nik=# select openai_chat('tell me about fixes of CREATE INDEX CONCURRENTLY â€“ when, who, etc.');
openai_chat
There are two notable fixes for CREATE INDEX CONCURRENTLY. The first one was made on 2016-02-16 18:43:03+00 by Tom Lane, with the commit hash a65313f2. The commit improved the documentation about CREATE INDEX CONCURRENTLY, clarifying the description of which transactions will block a CREATE INDEX CONCURRENTLY command from proceeding.

The second fix was made on 2012-11-29 02:25:27+00, with the commit hash 3c840464. This commit fixed assorted bugs in CREATE/DROP INDEX CONCURRENTLY. The issue was that the pg_index state for an index that's reached the final pre-drop stage was the same as the state for an index just created by CREATE INDEX CONCURRENTLY. This was fixed by adding an additional boolean column "indislive" to pg_index.
```

è¯·æ³¨æ„ï¼Œå®ƒé»˜è®¤ä½¿ç”¨æ¨¡å‹ "gpt-4"ï¼Œå®ƒæ¯” "gpt-3.5-turbo-16k" æ›´æ…¢ä¸”æ›´æ˜‚è´µ (è¯·å‚è€ƒ[å®šä»·](https://openai.com/pricing))ã€‚

## ä¸€äº›æ³¨æ„äº‹é¡¹

1. æ­£å¦‚å‰é¢æåˆ°çš„ï¼Œä» Postgres ä¸­è°ƒç”¨å¤–éƒ¨ API çš„è¿™ç§æ–¹æ³•æ‰©å±•æ€§ä¸ä½³ã€‚å®ƒé€‚åˆå¿«é€ŸåŸå‹å¼€å‘ï¼Œä½†ä¸åº”åœ¨ TPS é¢„è®¡ä¼šæ˜¾è‘—å¢é•¿çš„é¡¹ç›®ä¸­ä½¿ç”¨ (å¦åˆ™ï¼Œéšç€è§„æ¨¡å¢é•¿ï¼ŒCPU é¥±å’Œã€ç©ºé—²äº‹åŠ¡é«˜å³°ç­‰é—®é¢˜å¯èƒ½å¯¼è‡´ä¸¥é‡çš„æ€§èƒ½é—®é¢˜ç”šè‡³å®•æœº)ã€‚
2. å¦ä¸€ä¸ªç¼ºç‚¹æ˜¯ `plpython3u` åœ¨æŸäº› Postgres æœåŠ¡ä¸Šä¸å¯ç”¨ (ä¾‹å¦‚ RDS)ã€‚
3. æœ€åï¼Œåœ¨ SQL ä¸Šä¸‹æ–‡ä¸­å·¥ä½œæ—¶ï¼Œå¾ˆå®¹æ˜“æ— æ„ä¸­åœ¨å¾ªç¯ä¸­è°ƒç”¨ APIã€‚è¿™å¯èƒ½å¯¼è‡´è¿‡åº¦å¼€é”€ã€‚ä¸ºé¿å…æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦ä»”ç»†æ£€æŸ¥æ‰§è¡Œè®¡åˆ’ã€‚
4. å¯¹äºæŸäº›äººæ¥è¯´ï¼Œè¿™ç±»ä»£ç ä¹Ÿå¯èƒ½æ›´éš¾è°ƒè¯•ã€‚

å°½ç®¡å¦‚æ­¤ï¼Œä¸Šè¿°æ¦‚å¿µåœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½éå¸¸æœ‰æ•ˆ â€” åªéœ€è®°ä½è¿™äº›ç»†èŠ‚ï¼Œé¿å…ä½æ•ˆæ“ä½œã€‚å¦‚æœé—®é¢˜è¿‡å¤§ï¼Œå¯ä»¥å°† API è°ƒç”¨ä»£ç ä» `plpython3u` ç§»åˆ° Postgres ä¹‹å¤–ã€‚